{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60da47e2-4450-4e8c-8cb4-85204b4c38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b19385-abf8-4ce6-9b72-0cb44df9ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots = pd.read_csv(\"shots.csv\") # original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453dcf71-359a-49cc-808f-af1715ec77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert shot type to numeric shot value\n",
    "all_shots[\"SHOT_VALUE\"] = all_shots[\"SHOT_TYPE\"].apply(lambda x: 3 if \"3PT\" in x else 2)\n",
    "\n",
    "all_shots = all_shots.drop(columns=[], errors = 'ignore')\n",
    "\n",
    "# Removing variables which will never be necessary, even if some moderatley improve accuracy (i.e like backourt shots being missed\n",
    "# details like these are not significant for coaching staff\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"GRID_TYPE\",\n",
    "    \"SHOT_ATTEMPTED_FLAG\",\n",
    "    \"PLAYER_ID\",\n",
    "    \"TEAM_ID\",\n",
    "    \"EVENT_TYPE\",\n",
    "    \"GAME_DATE\",\n",
    "    \"HTM\",\n",
    "    \"VTM\",\n",
    "    \"GAME_ID\",\n",
    "    \"GAME_EVENT_ID\",\n",
    "    \"LOC_X\",\n",
    "    \"LOC_Y\", \n",
    "    \"MINUTES_REMAINING\", \n",
    "    \"SECONDS_REMAINING\", \n",
    "    \"SHOT_TYPE\",\n",
    "    \"PERIOD\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84af4c3c-9bb0-4e06-aab0-189fe16d2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     443.000000\n",
      "mean      463.968397\n",
      "std       357.667423\n",
      "min         2.000000\n",
      "25%       174.500000\n",
      "50%       388.000000\n",
      "75%       691.500000\n",
      "max      1617.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SHOT FREQUENCY OF EACH PLAYER\n",
    "\n",
    "player_counts = all_shots['PLAYER_NAME'].value_counts()\n",
    "print(player_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47a6542-72e1-40da-9f00-07c253525c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     332.000000\n",
      "mean      594.015060\n",
      "std       319.866215\n",
      "min       175.000000\n",
      "25%       336.500000\n",
      "50%       512.500000\n",
      "75%       781.000000\n",
      "max      1617.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count shots per player\n",
    "player_counts = all_shots['PLAYER_NAME'].value_counts()\n",
    "\n",
    "# Keep only players with 175 or more shots\n",
    "players_to_keep = player_counts[player_counts >= 175].index\n",
    "\n",
    "# Filter the dataframe\n",
    "all_shots = all_shots[all_shots['PLAYER_NAME'].isin(players_to_keep)].copy()\n",
    "\n",
    "player_counts = all_shots['PLAYER_NAME'].value_counts()\n",
    "print(player_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9321b7d-6a91-4384-97fc-fb1dad204c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL DATASET CLEANED\n",
    "all_shots_clean = all_shots.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Keep only players with 174 or more shots\n",
    "players_to_keep = player_counts[player_counts >= 174].index\n",
    "\n",
    "# Filter the dataframe\n",
    "all_shots_clean = all_shots_clean[all_shots_clean['PLAYER_NAME'].isin(players_to_keep)].copy()\n",
    "\n",
    "# COMBINES THREE SHOT DESCRIPTORS INTO ONE\n",
    "all_shots_zones_comb = all_shots_clean.copy()\n",
    "all_shots_zones_comb['SHOT_ZONE'] = all_shots_zones_comb['SHOT_ZONE_BASIC'] + \" - \" + all_shots_zones_comb['SHOT_ZONE_AREA']\n",
    "all_shots_zones_comb = all_shots_zones_comb.drop(columns=[\"SHOT_ZONE_BASIC\",\"SHOT_ZONE_AREA\",\"SHOT_ZONE_RANGE\"], errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4e1fe8-e16c-4187-b9ce-25732b69370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW ZONE REDUCTION (difference between orig & _zones dataframes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57f4dfd-299b-4d9d-909c-1e6b3802a4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         SHOT_ZONE_BASIC         SHOT_ZONE_AREA  SHOT_ZONE_RANGE\n",
      "0      Above the Break 3  Right Side Center(RC)          24+ ft.\n",
      "1              Mid-Range   Left Side Center(LC)        16-24 ft.\n",
      "2        Restricted Area          Right Side(R)  Less Than 8 ft.\n",
      "3  In The Paint (Non-RA)              Center(C)         8-16 ft.\n",
      "4         Right Corner 3           Left Side(L)  Back Court Shot\n",
      "5          Left Corner 3         Back Court(BC)                 \n",
      "6              Backcourt                                        \n"
     ]
    }
   ],
   "source": [
    "cols = [\"SHOT_ZONE_BASIC\", \"SHOT_ZONE_AREA\", \"SHOT_ZONE_RANGE\"]\n",
    "\n",
    "# Get unique values for each column\n",
    "unique_lists = [list(all_shots_clean[col].unique()) for col in cols]\n",
    "\n",
    "# Find max length to pad shorter lists\n",
    "max_len = max(len(lst) for lst in unique_lists)\n",
    "\n",
    "# Pad each list with empty strings so they align\n",
    "padded_lists = [lst + [\"\"]*(max_len - len(lst)) for lst in unique_lists]\n",
    "\n",
    "# Combine into a DataFrame\n",
    "unique_df = pd.DataFrame({col: padded for col, padded in zip(cols, padded_lists)})\n",
    "\n",
    "print(unique_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1067bfd2-a656-4145-baca-adba57e78e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted Area - Center(C): 63602  (32.25%)\n",
      "In The Paint (Non-RA) - Center(C): 24902  (12.63%)\n",
      "Above the Break 3 - Left Side Center(LC): 15834  (8.03%)\n",
      "Above the Break 3 - Right Side Center(RC): 15116  (7.66%)\n",
      "Mid-Range - Left Side(L): 12430  (6.30%)\n",
      "Mid-Range - Right Side(R): 11968  (6.07%)\n",
      "Above the Break 3 - Center(C): 10428  (5.29%)\n",
      "Mid-Range - Center(C): 9124  (4.63%)\n",
      "Mid-Range - Right Side Center(RC): 7737  (3.92%)\n",
      "Left Corner 3 - Left Side(L): 7458  (3.78%)\n",
      "Mid-Range - Left Side Center(LC): 7338  (3.72%)\n",
      "Right Corner 3 - Right Side(R): 7006  (3.55%)\n",
      "In The Paint (Non-RA) - Left Side(L): 1990  (1.01%)\n",
      "In The Paint (Non-RA) - Right Side(R): 1830  (0.93%)\n",
      "Backcourt - Back Court(BC): 397  (0.20%)\n",
      "Above the Break 3 - Back Court(BC): 53  (0.03%)\n"
     ]
    }
   ],
   "source": [
    "zone_counts = all_shots_zones_comb[\"SHOT_ZONE\"].value_counts()\n",
    "zone_percent = zone_counts / zone_counts.sum() * 100\n",
    "\n",
    "for zone, count in zone_counts.items():\n",
    "    pct = zone_percent[zone]\n",
    "    print(f\"{zone}: {count}  ({pct:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011dc9b6-b848-4269-8894-05f41572f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN REMOVE BACKCOURT CHOTS HERE\n",
    "all_shots_clean_ = all_shots_clean[\n",
    "    ~(\n",
    "        all_shots_clean['SHOT_ZONE_BASIC'].str.contains('Backcourt', na=False) |\n",
    "        all_shots_clean['SHOT_ZONE_AREA'].str.contains('Back Court', na=False) |\n",
    "        all_shots_clean['SHOT_ZONE_RANGE'].str.contains('Back Court', na=False)\n",
    "    )\n",
    "]\n",
    "\n",
    "all_shots_zones_comb = all_shots_zones_comb[~all_shots_zones_comb ['SHOT_ZONE'].str.contains('Back Court', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440bb303-86c7-4f4b-b6ac-e6b06075bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW SHOT CATEGORIZATION (difference between orig & _cat dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442a2cef-570b-4a4a-9300-266d6151c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Count  Percentage\n",
      "ACTION_TYPE                                      \n",
      "Jump Shot                       93487   54.203846\n",
      "Layup Shot                      17102    9.915755\n",
      "Driving Layup Shot              12488    7.240554\n",
      "Pullup Jump shot                11781    6.830634\n",
      "Floating Jump shot               4954    2.872334\n",
      "Hook Shot                        4430    2.568518\n",
      "Step Back Jump shot              4334    2.512857\n",
      "Tip Layup Shot                   3888    2.254266\n",
      "Running Layup Shot               3432    1.989877\n",
      "Turnaround Jump Shot             3393    1.967264\n",
      "Cutting Layup Shot               3041    1.763175\n",
      "Dunk Shot                        3002    1.740562\n",
      "Fadeaway Jump Shot               2891    1.676204\n",
      "Driving Finger Roll Layup Shot   2134    1.237295\n",
      "Driving Floating Jump Shot       2116    1.226859\n"
     ]
    }
   ],
   "source": [
    "# Compute proportions of each action type\n",
    "action_props = all_shots_clean[\"ACTION_TYPE\"].value_counts(normalize=True)\n",
    "\n",
    "# Identify action types >= 1%\n",
    "top_actions = action_props[action_props >= 0.01].index\n",
    "\n",
    "# Filter the dataframe to only keep top actions\n",
    "actions_filtered = all_shots_clean[all_shots_clean[\"ACTION_TYPE\"].isin(top_actions)].copy()\n",
    "\n",
    "# Recalculate counts and percentages after filtering\n",
    "action_counts = actions_filtered[\"ACTION_TYPE\"].value_counts()\n",
    "action_percentages = actions_filtered[\"ACTION_TYPE\"].value_counts(normalize=True) * 100  # percentage\n",
    "\n",
    "# Combine into a single dataframe for easy viewing\n",
    "action_summary = pd.DataFrame({\n",
    "    \"Count\": action_counts,\n",
    "    \"Percentage\": action_percentages\n",
    "})\n",
    "\n",
    "print(action_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3ed495-91af-4ba1-83e1-6e2df7853441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE NO SHOT / OTHER SHOT \n",
    "all_shots_zones_comb = all_shots_zones_comb[~all_shots_zones_comb['ACTION_TYPE'].str.contains('No Shot', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095a5505-0a2f-4b4a-92ac-cf72890104c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO CSVs\n",
    "\n",
    "# Merged zones, 57 shot types\n",
    "all_shots_zones_comb.to_csv(\"shots_for_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d499eca-4bc1-4867-a33b-02cffc6d297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter Tuning for XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2202af4d-611e-4244-8261-6036cb60215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = pd.read_csv(\"shots_for_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5da04f4-c71d-4141-8bae-d61a27692081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== shots ===\n",
      "['PLAYER_NAME', 'TEAM_NAME', 'ACTION_TYPE', 'SHOT_DISTANCE', 'SHOT_MADE_FLAG', 'SHOT_VALUE', 'SHOT_ZONE']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== shots ===\")\n",
    "print(list(shots.columns))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbef100a-20f0-403e-88b3-1adbd283aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 97\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, X_test, y_test, y_proba, accuracy, f1\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# RUN\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m best_model, X_test, y_test, y_proba, acc, f1 \u001b[38;5;241m=\u001b[39m train_xgb_tuned(shots, features, target)\n",
      "Cell \u001b[1;32mIn[19], line 76\u001b[0m, in \u001b[0;36mtrain_xgb_tuned\u001b[1;34m(shots, features, target)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Train/test split\u001b[39;00m\n\u001b[0;32m     72\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     73\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     74\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     77\u001b[0m best_model \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1952\u001b[0m         ParameterSampler(\n\u001b[0;32m   1953\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1954\u001b[0m         )\n\u001b[0;32m   1955\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1683\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1661\u001b[0m model, metric, params, feature_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1662\u001b[0m     xgb_model, params, feature_weights\n\u001b[0;32m   1663\u001b[0m )\n\u001b[0;32m   1664\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1665\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1666\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1680\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1681\u001b[0m )\n\u001b[1;32m-> 1683\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1684\u001b[0m     params,\n\u001b[0;32m   1685\u001b[0m     train_dmatrix,\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1687\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1688\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1689\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1690\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1691\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1692\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1693\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1694\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1695\u001b[0m )\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2246\u001b[0m     _check_call(\n\u001b[1;32m-> 2247\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2249\u001b[0m         )\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_label_encoder.*\")\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# DATA & FEATURES\n",
    "# --------------------------\n",
    "features = [\n",
    "    \"PLAYER_NAME\", \"TEAM_NAME\", \n",
    "    \"ACTION_TYPE\", \"SHOT_ZONE\", \"SHOT_DISTANCE\"\n",
    "]\n",
    "\n",
    "target = \"SHOT_MADE_FLAG\"\n",
    "\n",
    "# --------------------------\n",
    "# PARAM GRID (same as before)\n",
    "# --------------------------\n",
    "param_grid = {\n",
    "    \"xgb__n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"xgb__max_depth\": [3, 5, 8, 10, 12],\n",
    "    \"xgb__learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    \"xgb__subsample\": [0.5, 0.75, 1.0],\n",
    "    \"xgb__colsample_bytree\": [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# TRAIN + TUNE\n",
    "# --------------------------\n",
    "def train_xgb_tuned(shots, features, target):\n",
    "    X = shots[features]\n",
    "    y = shots[target]\n",
    "\n",
    "    # Detect categorical vars\n",
    "    cat_features = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    # Base pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=1, \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Randomized search using F1\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        scoring=make_scorer(f1_score),\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # Evaluate\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "    accuracy = best_model.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.3f} | F1: {f1:.3f}\")\n",
    "\n",
    "    return best_model, X_test, y_test, y_proba, accuracy, f1\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# RUN\n",
    "# --------------------------\n",
    "best_model, X_test, y_test, y_proba, acc, f1 = train_xgb_tuned(shots, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41326a55-4861-473c-b4e2-1669d0407732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round of tuning, Best: Accuracy: 0.654 | F1: 0.559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def43da-e6b1-49b9-b146-9de986bd4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# DATA & FEATURES\n",
    "# --------------------------\n",
    "features = [\n",
    "    \"PLAYER_NAME\", \n",
    "    \"TEAM_NAME\", # significant because of coaching style and shot selection\n",
    "    \"ACTION_TYPE\", \"SHOT_ZONE\",\n",
    "    \"SHOT_DISTANCE\" # more precise insight into tendencies\n",
    "]\n",
    "\n",
    "target = \"SHOT_MADE_FLAG\"\n",
    "\n",
    "# --------------------------\n",
    "# PARAM GRID \n",
    "# --------------------------\n",
    "\n",
    "param_grid2 = {\n",
    "        \"xgb__n_estimators\": [650, 750, 850],\n",
    "        \"xgb__max_depth\": [6, 7, 8, 9],\n",
    "        \"xgb__learning_rate\": [0.15, 0.2, 0.25],\n",
    "        \"xgb__subsample\": [0.25, 0.5, 0.75],\n",
    "        \"xgb__colsample_bytree\": [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# TRAIN + TUNE\n",
    "# --------------------------\n",
    "def train_xgb_tuned2(shots, features, target):\n",
    "    X = shots[features]\n",
    "    y = shots[target]\n",
    "\n",
    "    # Detect categorical vars\n",
    "    cat_features = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    # Base pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=1, \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Randomized search using F1\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_distributions=param_grid2,\n",
    "        n_iter=20,\n",
    "        scoring=make_scorer(f1_score),\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # Evaluate\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "    accuracy = best_model.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.3f} | F1: {f1:.3f}\")\n",
    "\n",
    "    return best_model, X_test, y_test, y_proba, accuracy, f1\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# RUN\n",
    "# --------------------------\n",
    "best_model, X_test, y_test, y_proba, acc, f1 = train_xgb_tuned2(shots, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c5d3a-620a-494a-97be-522adeb1c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Top 3 teams by Accuracy when trained on league wide data\n",
    "# --------------------------\n",
    "top_acc = sorted(team_results.items(), key=lambda x: x[1][\"accuracy\"], reverse=True)[:3]\n",
    "print(\"Top 3 Teams by Accuracy:\")\n",
    "for team, metrics in top_acc:\n",
    "    print(f\"{team}: Accuracy={metrics['accuracy']:.3f}, F1={metrics['f1']:.3f}\")\n",
    "\n",
    "# --------------------------\n",
    "# Top 3 teams by F1\n",
    "# --------------------------\n",
    "top_f1 = sorted(team_results.items(), key=lambda x: x[1][\"f1\"], reverse=True)[:3]\n",
    "print(\"\\nTop 3 Teams by F1:\")\n",
    "for team, metrics in top_f1:\n",
    "    print(f\"{team}: Accuracy={metrics['accuracy']:.3f}, F1={metrics['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f824b-8611-4253-8092-3e92e8be0f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c104a-4f47-4986-a084-9948045c00fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a955de-b24f-4ccf-962a-c699e15ad386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
