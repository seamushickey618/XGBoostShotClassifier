{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60da47e2-4450-4e8c-8cb4-85204b4c38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b19385-abf8-4ce6-9b72-0cb44df9ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots = pd.read_csv(\"shots.csv\") # original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453dcf71-359a-49cc-808f-af1715ec77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert shot type to numeric shot value\n",
    "all_shots[\"SHOT_VALUE\"] = all_shots[\"SHOT_TYPE\"].apply(lambda x: 3 if \"3PT\" in x else 2)\n",
    "\n",
    "all_shots = all_shots.drop(columns=[], errors = 'ignore')\n",
    "\n",
    "# Removing variables which will never be necessary, even if some moderatley improve accuracy (i.e like backourt shots being missed\n",
    "# details like these are not significant for coaching staff\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"GRID_TYPE\",\n",
    "    \"SHOT_ATTEMPTED_FLAG\",\n",
    "    \"PLAYER_ID\",\n",
    "    \"TEAM_ID\",\n",
    "    \"EVENT_TYPE\",\n",
    "    \"GAME_DATE\",\n",
    "    \"HTM\",\n",
    "    \"VTM\",\n",
    "    \"GAME_ID\",\n",
    "    \"GAME_EVENT_ID\",\n",
    "    \"LOC_X\",\n",
    "    \"LOC_Y\", \n",
    "    \"MINUTES_REMAINING\", \n",
    "    \"SECONDS_REMAINING\", \n",
    "    \"SHOT_TYPE\",\n",
    "    \"PERIOD\", \n",
    "    \"SHOT_DISTANCE\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84af4c3c-9bb0-4e06-aab0-189fe16d2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     443.000000\n",
      "mean      463.968397\n",
      "std       357.667423\n",
      "min         2.000000\n",
      "25%       174.500000\n",
      "50%       388.000000\n",
      "75%       691.500000\n",
      "max      1617.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SHOT FREQUENCY OF EACH PLAYER\n",
    "\n",
    "player_counts = all_shots['PLAYER_NAME'].value_counts()\n",
    "print(player_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47a6542-72e1-40da-9f00-07c253525c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     332.000000\n",
      "mean      594.015060\n",
      "std       319.866215\n",
      "min       175.000000\n",
      "25%       336.500000\n",
      "50%       512.500000\n",
      "75%       781.000000\n",
      "max      1617.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count shots per player\n",
    "player_counts = all_shots['PLAYER_NAME'].value_counts()\n",
    "\n",
    "# Keep only players with 175 or more shots\n",
    "players_to_keep = player_counts[player_counts >= 175].index\n",
    "\n",
    "# Filter the dataframe\n",
    "all_shots = all_shots[all_shots['PLAYER_NAME'].isin(players_to_keep)].copy()\n",
    "\n",
    "player_counts = all_shots['PLAYER_NAME'].value_counts()\n",
    "print(player_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9321b7d-6a91-4384-97fc-fb1dad204c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL DATASET CLEANED\n",
    "all_shots_clean = all_shots.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Keep only players with 174 or more shots\n",
    "players_to_keep = player_counts[player_counts >= 174].index\n",
    "\n",
    "# Filter the dataframe\n",
    "all_shots_clean = all_shots_clean[all_shots_clean['PLAYER_NAME'].isin(players_to_keep)].copy()\n",
    "\n",
    "# COMBINES THREE SHOT DESCRIPTORS INTO ONE\n",
    "all_shots_zones_comb = all_shots_clean.copy()\n",
    "all_shots_zones_comb['SHOT_ZONE'] = all_shots_zones_comb['SHOT_ZONE_BASIC'] + \" - \" + all_shots_zones_comb['SHOT_ZONE_AREA']\n",
    "all_shots_zones_comb = all_shots_zones_comb.drop(columns=[\"SHOT_ZONE_BASIC\",\"SHOT_ZONE_AREA\",\"SHOT_ZONE_RANGE\"], errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4e1fe8-e16c-4187-b9ce-25732b69370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW ZONE REDUCTION (difference between orig & _zones dataframes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57f4dfd-299b-4d9d-909c-1e6b3802a4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         SHOT_ZONE_BASIC         SHOT_ZONE_AREA  SHOT_ZONE_RANGE\n",
      "0      Above the Break 3  Right Side Center(RC)          24+ ft.\n",
      "1              Mid-Range   Left Side Center(LC)        16-24 ft.\n",
      "2        Restricted Area          Right Side(R)  Less Than 8 ft.\n",
      "3  In The Paint (Non-RA)              Center(C)         8-16 ft.\n",
      "4         Right Corner 3           Left Side(L)  Back Court Shot\n",
      "5          Left Corner 3         Back Court(BC)                 \n",
      "6              Backcourt                                        \n"
     ]
    }
   ],
   "source": [
    "cols = [\"SHOT_ZONE_BASIC\", \"SHOT_ZONE_AREA\", \"SHOT_ZONE_RANGE\"]\n",
    "\n",
    "# Get unique values for each column\n",
    "unique_lists = [list(all_shots_clean[col].unique()) for col in cols]\n",
    "\n",
    "# Find max length to pad shorter lists\n",
    "max_len = max(len(lst) for lst in unique_lists)\n",
    "\n",
    "# Pad each list with empty strings so they align\n",
    "padded_lists = [lst + [\"\"]*(max_len - len(lst)) for lst in unique_lists]\n",
    "\n",
    "# Combine into a DataFrame\n",
    "unique_df = pd.DataFrame({col: padded for col, padded in zip(cols, padded_lists)})\n",
    "\n",
    "print(unique_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1067bfd2-a656-4145-baca-adba57e78e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted Area - Center(C): 63602  (32.25%)\n",
      "In The Paint (Non-RA) - Center(C): 24902  (12.63%)\n",
      "Above the Break 3 - Left Side Center(LC): 15834  (8.03%)\n",
      "Above the Break 3 - Right Side Center(RC): 15116  (7.66%)\n",
      "Mid-Range - Left Side(L): 12430  (6.30%)\n",
      "Mid-Range - Right Side(R): 11968  (6.07%)\n",
      "Above the Break 3 - Center(C): 10428  (5.29%)\n",
      "Mid-Range - Center(C): 9124  (4.63%)\n",
      "Mid-Range - Right Side Center(RC): 7737  (3.92%)\n",
      "Left Corner 3 - Left Side(L): 7458  (3.78%)\n",
      "Mid-Range - Left Side Center(LC): 7338  (3.72%)\n",
      "Right Corner 3 - Right Side(R): 7006  (3.55%)\n",
      "In The Paint (Non-RA) - Left Side(L): 1990  (1.01%)\n",
      "In The Paint (Non-RA) - Right Side(R): 1830  (0.93%)\n",
      "Backcourt - Back Court(BC): 397  (0.20%)\n",
      "Above the Break 3 - Back Court(BC): 53  (0.03%)\n"
     ]
    }
   ],
   "source": [
    "zone_counts = all_shots_zones_comb[\"SHOT_ZONE\"].value_counts()\n",
    "zone_percent = zone_counts / zone_counts.sum() * 100\n",
    "\n",
    "for zone, count in zone_counts.items():\n",
    "    pct = zone_percent[zone]\n",
    "    print(f\"{zone}: {count}  ({pct:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011dc9b6-b848-4269-8894-05f41572f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN REMOVE BACKCOURT CHOTS HERE\n",
    "all_shots_zones_comb = all_shots_zones_comb[~all_shots_zones_comb ['SHOT_ZONE'].str.contains('Back Court', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "440bb303-86c7-4f4b-b6ac-e6b06075bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW SHOT CATEGORIZATION (difference between orig & _cat dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442a2cef-570b-4a4a-9300-266d6151c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Count  Percentage  MadePercentage\n",
      "ACTION_TYPE                                                      \n",
      "Dunk Shot                        3002    1.744608       86.842105\n",
      "Cutting Layup Shot               3041    1.767273       80.170996\n",
      "Driving Finger Roll Layup Shot   2134    1.240171       74.695408\n",
      "Running Layup Shot               3432    1.994502       73.484848\n",
      "Driving Layup Shot              12488    7.257385       61.082639\n",
      "Pullup Jump shot                11779    6.845351       53.892521\n",
      "Driving Floating Jump Shot       2112    1.227386       51.136364\n",
      "Floating Jump shot               4953    2.878430       49.101555\n",
      "Step Back Jump shot              4334    2.518698       48.823258\n",
      "Tip Layup Shot                   3888    2.259506       47.222222\n",
      "Hook Shot                        4430    2.574489       45.304740\n",
      "Fadeaway Jump Shot               2890    1.679520       44.948097\n",
      "Turnaround Jump Shot             3393    1.971838       42.793988\n",
      "Layup Shot                      17102    9.938805       40.445562\n",
      "Jump Shot                       93095   54.102038       32.380901\n"
     ]
    }
   ],
   "source": [
    "# Compute proportions of each action type\n",
    "action_props = all_shots_zones_comb[\"ACTION_TYPE\"].value_counts(normalize=True)\n",
    "\n",
    "# Identify action types >= 1%\n",
    "top_actions = action_props[action_props >= 0.01].index\n",
    "\n",
    "# Filter the dataframe to only keep top actions\n",
    "actions_filtered = all_shots_zones_comb[all_shots_zones_comb[\"ACTION_TYPE\"].isin(top_actions)].copy()\n",
    "\n",
    "# Recalculate counts and percentages after filtering\n",
    "action_counts = actions_filtered[\"ACTION_TYPE\"].value_counts()\n",
    "action_percentages = actions_filtered[\"ACTION_TYPE\"].value_counts(normalize=True) * 100  # percentage\n",
    "\n",
    "# Calculate % of shots made for each action type\n",
    "action_shot_made_pct = actions_filtered.groupby(\"ACTION_TYPE\")[\"SHOT_MADE_FLAG\"].mean() * 100\n",
    "\n",
    "# Combine into a single dataframe for easy viewing\n",
    "action_summary = pd.DataFrame({\n",
    "    \"Count\": action_counts,\n",
    "    \"Percentage\": action_percentages,\n",
    "    \"MadePercentage\": action_shot_made_pct\n",
    "})\n",
    "\n",
    "# Sort by Count descending for readability\n",
    "action_summary = action_summary.sort_values(by=\"MadePercentage\", ascending=False)\n",
    "\n",
    "print(action_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095a5505-0a2f-4b4a-92ac-cf72890104c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO CSVs\n",
    "\n",
    "# Merged zones, 57 shot types\n",
    "all_shots_zones_comb.to_csv(\"shots_for_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d499eca-4bc1-4867-a33b-02cffc6d297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter Tuning for XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2202af4d-611e-4244-8261-6036cb60215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = pd.read_csv(\"shots_for_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5da04f4-c71d-4141-8bae-d61a27692081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== shots ===\n",
      "['PLAYER_NAME', 'TEAM_NAME', 'ACTION_TYPE', 'SHOT_MADE_FLAG', 'SHOT_VALUE', 'SHOT_ZONE']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== shots ===\")\n",
    "print(list(shots.columns))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbef100a-20f0-403e-88b3-1adbd283aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'xgb__subsample': 0.5, 'xgb__n_estimators': 1000, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.1, 'xgb__colsample_bytree': 0.5}\n",
      "\n",
      "Predicted Overall Shot Success: 0.4551987350\n",
      "Actual Overall Shot Success: 0.4543745077\n",
      "\n",
      "Accuracy: 0.646 | F1 Score: 0.552\n",
      "Log Loss: 0.6253 (lower is better; measures how well predicted probabilities match actual outcomes)\n",
      "Brier Score: 0.2185 (lower is better; mean squared error of predicted probabilities)\n",
      "AUC-ROC: 0.687 (1.0 = perfect ranking of shots, 0.5 = random)\n",
      "Calibration curve indicates probability reliability.\n",
      "Points on diagonal = well-calibrated; above = underestimates; below = overestimates.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, log_loss, brier_score_loss, roc_auc_score, make_scorer\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_label_encoder.*\")\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# DATA & FEATURES\n",
    "# --------------------------\n",
    "features = [\n",
    "    \"PLAYER_NAME\", \"TEAM_NAME\", \n",
    "    \"ACTION_TYPE\", \"SHOT_ZONE\"\n",
    "]\n",
    "\n",
    "target = \"SHOT_MADE_FLAG\"\n",
    "\n",
    "# --------------------------\n",
    "# PARAM GRID (same as before)\n",
    "# --------------------------\n",
    "param_grid = {\n",
    "    \"xgb__n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"xgb__max_depth\": [3, 5, 8, 10, 12],\n",
    "    \"xgb__learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    \"xgb__subsample\": [0.5, 0.75, 1.0],\n",
    "    \"xgb__colsample_bytree\": [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# TRAIN + TUNE\n",
    "# --------------------------\n",
    "def train_xgb_tuned(shots, features, target, param_grid):\n",
    "    \"\"\"\n",
    "    Train an XGBoost classifier with hyperparameter tuning and report multiple evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - shots: pd.DataFrame, dataset including features and target\n",
    "    - features: list, column names to use as features\n",
    "    - target: str, name of the target column\n",
    "    - param_grid: dict, hyperparameter search space for RandomizedSearchCV\n",
    "\n",
    "    Returns:\n",
    "    - best_model: trained XGBClassifier pipeline\n",
    "    - X_test, y_test: test set\n",
    "    - y_proba: predicted probabilities for the positive class\n",
    "    - accuracy, f1, logloss, brier, auc: evaluation metrics\n",
    "    - predicted_success_rate, actual_success_rate: overall shot success\n",
    "    \"\"\"\n",
    "    # --------------------------\n",
    "    # Prepare data\n",
    "    # --------------------------\n",
    "    X = shots[features]\n",
    "    y = shots[target]\n",
    "\n",
    "    # Identify categorical features\n",
    "    cat_features = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # Pipeline\n",
    "    # --------------------------\n",
    "    pipeline = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"xgb\", XGBClassifier(eval_metric=\"logloss\", n_jobs=1, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # --------------------------\n",
    "    # Train/test split\n",
    "    # --------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # Randomized hyperparameter search\n",
    "    # --------------------------\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        scoring=make_scorer(f1_score),\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # --------------------------\n",
    "    # Predictions\n",
    "    # --------------------------\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "    # --------------------------\n",
    "    # Standard metrics\n",
    "    # --------------------------\n",
    "    accuracy = best_model.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # --------------------------\n",
    "    # Probability-based metrics\n",
    "    # --------------------------\n",
    "    logloss = log_loss(y_test, y_proba)\n",
    "    brier = brier_score_loss(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # --------------------------\n",
    "    # Overall predicted vs actual shot success\n",
    "    # --------------------------\n",
    "    predicted_success_rate = np.mean(y_proba)\n",
    "    actual_success_rate = np.mean(y_test)\n",
    "\n",
    "    # --------------------------\n",
    "    # Print metrics with interpretation\n",
    "    # --------------------------\n",
    "    print(f\"\\nPredicted Overall Shot Success: {predicted_success_rate:.10f}\")\n",
    "    print(f\"Actual Overall Shot Success: {actual_success_rate:.10f}\")\n",
    "    print(f\"\\nAccuracy: {accuracy:.3f} | F1 Score: {f1:.3f}\")\n",
    "    print(f\"Log Loss: {logloss:.4f} (lower is better; measures how well predicted probabilities match actual outcomes)\")\n",
    "    print(f\"Brier Score: {brier:.4f} (lower is better; mean squared error of predicted probabilities)\")\n",
    "    print(f\"AUC-ROC: {auc:.3f} (1.0 = perfect ranking of shots, 0.5 = random)\")\n",
    "    print(\"Calibration curve indicates probability reliability.\\n\"\n",
    "          \"Points on diagonal = well-calibrated; above = underestimates; below = overestimates.\")\n",
    "\n",
    "    return best_model, X_test, y_test, y_proba, accuracy, f1, logloss, brier, auc, predicted_success_rate, actual_success_rate\n",
    "\n",
    "# --------------------------\n",
    "# Example run\n",
    "# --------------------------\n",
    "best_model, X_test, y_test, y_proba, acc, f1, logloss, brier, auc, predicted_success, actual_success = \\\n",
    "    train_xgb_tuned(shots, features, target, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f824b-8611-4253-8092-3e92e8be0f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c104a-4f47-4986-a084-9948045c00fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a955de-b24f-4ccf-962a-c699e15ad386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
